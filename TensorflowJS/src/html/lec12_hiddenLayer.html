<!DOCTYPE html>
<html>
 
<head>
    <title>TensorFlow.js Tutorial - boston housing </title>
 
    <!-- Import TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis"></script>
    <script src="../js/lec10_1boston.js"></script>
</head>
 
<body>
    <script>
        //hidden layer를 통해 딥러닝 다운 코드 구현하기

        /*
        var 보스톤_원인 = [
            [0.00632,18,2.31,0,0.538,6.575,65.2,4.09,1,296,15.3,396.9,4.98],
            [0.02731,0,7.07,0,0.469,6.421,78.9,4.9671,2,242,17.8,396.9,9.14]
        ];
        var 보스톤_결과 = [
            [24], 
            [21.6]
        ];*/
        
     
        // 1. 과거의 데이터를 준비합니다. 
        var 원인 = tf.tensor(보스톤_원인);
        var 결과 = tf.tensor(보스톤_결과);
 
        // 2. 모델의 모양을 만듭니다. 
        var X = tf.input({ shape: [13] }); //input layer
        var H1 = tf.layers.dense({ units: 13, activation:'relu' }).apply(X); //hidden layer1
        var H2 = tf.layers.dense({ units: 13, activation:'relu' }).apply(H1); //hidden layer2 
        var Y = tf.layers.dense({ units: 1 }).apply(H2); //output layer
        /*여태까지 입력, 출력 개수라고 불러오던 것이 각각 input layer, output layer 생성 코드였던것
          그러므로 논리상 hidden layer를 추가한다면 그 둘의 사이가 되겠지
          이때 apply(?)를 통해 H1은 X에, H2는 H1에, Y는 H2에 연결하고 있다
          그림상에서의 연결선이었던 것에 해당하기 때문에 이게 없으면 작동을 안하겠지
          그리고 저거 hidden layer 하나만 놔두고 X-H-Y로 연결해도됨 */

        /*이제 hidden layer 내부에 노드는 몇개를 할건지 units로 정해줘야됨
          정해진건 없지만 일반적으로 입력층과 출력층 사이의 값을 입력한다
          그 그림 떠올려보면 항상 입력층 노드개수 엄청 많고 출력층 노드개수 거의 1~2개고
          은닉층은 그 중간정도의 개수를 가져서 나아갈수록 줄어드는 모양이었지
          그게 여기에도 반영됐다고 생각하면 됨 그리고 저 개수에 따라 성능이 달라지니
          지금은 일단 13으로 하지만 이후 테스트롤 통해 이 값을 조정해나가겠지*/

        /*은닉층에는 입출력층과 다르게 activation함수를 지정해줘야한다
          실질적으로 연산이 일어나야 하기에 어떤 방식을 택할지를 알아야하기 때문인것같음
          어떻게 입력하는지는 설명 홈페이지에 dense탭에 들어가면 알 수 있다 어떤식으로
          함수를 쓰면 되는지 나와있기 때문 activation ('elu | 'hardSignoid' | 'relu'..)
          등이 적혀있는데 이 | 선으로 구분된것들이 다 내가 실제로 쓸 수 있는 activation
          함수값들이다 저 방식들 뭔가 데이터분석 공부할때 들어본듯 softmax같은거
          뭘로 해줘야할지 모르겠으면 그냥 relu 쓰면 된다 전설적인 activation function이다*/
        var model = tf.model({ inputs: X, outputs: Y });
        var compileParam = { optimizer: tf.train.adam(), loss: tf.losses.meanSquaredError }
        model.compile(compileParam);
        tfvis.show.modelSummary({name:'요약', tab:'모델'}, model);
 
        // 3. 데이터로 모델을 학습시킵니다. 
//         var fitParam = {epochs: 100}
        var _history = [];
        var fitParam = { 
          epochs: 100, 
          callbacks:{
            onEpochEnd:
              function(epoch, logs){
                console.log('epoch', epoch, logs, 'RMSE=>', Math.sqrt(logs.loss));
                _history.push(logs);
                tfvis.show.history({name:'loss', tab:'역사'}, _history, ['loss']);
              }
          }
        } // loss 추가 예제
        model.fit(원인, 결과, fitParam).then(function (result) {
             
            // 4. 모델을 이용합니다. 
            // 4.1 기존의 데이터를 이용
            var 예측한결과 = model.predict(원인);
            예측한결과.print();
 
        });  
 
        // 4.2 새로운 데이터를 이용
        // var 다음주온도 = [15,16,17,18,19]
        // var 다음주원인 = tf.tensor(다음주온도);
        // var 다음주결과 = model.predict(다음주원인);
        // 다음주결과.print();
    </script>
</body>
 
</html>